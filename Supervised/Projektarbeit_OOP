import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.tree import export_graphviz,DecisionTreeClassifier
from sklearn.metrics import confusion_matrix
from sklearn.metrics import mean_absolute_error, mean_squared_error, accuracy_score, r2_score
import matplotlib.pyplot as plt
from sklearn.preprocessing import LabelEncoder
from sklearn.metrics import confusion_matrix
import seaborn as sns
import matplotlib.pyplot as plt
import numpy as np
from sklearn.svm import SVC
from sklearn.model_selection import GridSearchCV
from sklearn.metrics import accuracy_score, classification_report, precision_score
from sklearn.preprocessing import StandardScaler, Normalizer , RobustScaler
from sklearn.pipeline import make_pipeline


class base_class:
   def __init__(self, df, Y_class):
        self.target_names = ['class 0', 'class 1', 'class 2']
        self.Y_class = Y_class
        self.df = df
        # Train/Test split
        self.X_train, self.X_test, self.y_train, self.y_test = train_test_split(
            df, self.Y_class, test_size=0.2, random_state=42
        )
  
   def predicten(self):
      self.y_pred = self.model.predict(self.X_test)
      print(f"The Predicted Outputs are as follows: \n{self.y_pred}")


   def Confusion_mat(self):
      cm = confusion_matrix(self.y_test, self.y_pred)
      sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')
      plt.xlabel("Predicted")
      plt.ylabel("True")
      plt.show(block=False)

  

   def get_metrics_score(self):
       print(f"The calculated Accuracy Score of the {self.Name} Model is {accuracy_score(self.y_test ,self.y_pred)}")
       print(f"The Classification Report of the {self.Name} ist \n{classification_report(self.y_test,self.y_pred ,target_names=self.target_names)}")    
   


class RFC(base_class):
  
    def __init__(self, df, Y_class, name=None):
        super().__init__(df, Y_class)
        self.model = RandomForestClassifier(random_state=42)
        self.Name = "Random Forest Classifier" if name is None else name
        self.model.fit(self.X_train, self.y_train)
        self.y_pred = self.model.predict(self.X_test)
        self.model.feature_importances = self.feature_importance()
   
    def params_opt(self):

      parameters = {'n_estimators':[1000, 2500, 5000, 7500, 10000], 'max_depth':[30,35,45,50], "ccp_alpha":[0.01,0.1,1,10]}
      self.opt_model = GridSearchCV(self.model, parameters)
      self.opt_model.fit(self.X_train,self.y_train)

      self.y_pred_clf = self.opt_model.predict(self.X_test)

    def feature_importance(self):
      self.feature_importance = self.model.feature_importances_
      for feature,importance in zip(self.X_train.columns , self.feature_importance):
            # Feature with its Importances
          print(f"Feature: {feature} and the Importance : {importance} ")

        # Sorting the features
      sorted_indices = self.feature_importance.argsort()[::-1] # sorted in decreasing order
      sorted_importances = self.feature_importance[sorted_indices]

        #Create a Bar Plot of the feature Importances
      plt.figure(figsize = (10,6))
      plt.bar(range(self.X_train.shape[1]) , sorted_importances)
      plt.xticks( range(self.X_train.shape[1]), self.X_train.columns[sorted_indices], rotation=90)
      plt.title("Feature Importances")
      plt.show(block=False)

    def random_filter(self):  

      Ind = np.where(self.feature_importance < self.feature_importance[-1])
      Colname = self.df.columns[Ind]

      df1 = self.df.drop(columns=Colname) 
      df1 = df1.drop(columns= "Random_Variable")
      self.df1 = df1
      self.y_pred = self.model.predict(self.X_test)

      self.X_train, self.X_test, self.y_train, self.y_test = train_test_split(df1, self.Y_class, test_size=0.2, random_state=42)

      self.model = RandomForestClassifier(random_state= 42)
      self.model.fit(self.X_train , self.y_train)

      self.Confusion_mat()
      self.get_metrics_score()

class Dec_tree(base_class):
   
   def __init__(self,df,Y_class, feature_importances_ = None):
      super().__init__(df,Y_class)
      self.model = DecisionTreeClassifier(random_state= 42)
      self.Name = "Decision Tree"
      self.model.fit(self.X_train,self.y_train)
      self.y_pred = self.model.predict(self.X_test)
      self.feature_importance = feature_importances_

   def params_opt(self):

      parameters = {'n_estimators':[1000, 2500, 5000, 7500, 10000], 'max_depth':[10,100,500,1000], "ccp_alpha":[0.01,0.1,1,10]}
      self.opt_model = GridSearchCV(self.model, parameters)
      self.opt_model.fit(self.X_train,self.y_train)

      self.y_pred_clf = self.opt_model.predict(self.X_test)


   

      
class SVM_clf(base_class):
   def __init__(self,df,Y_class, feature_importances_ = None, name = None ,dec = None):
      super().__init__(df,Y_class)

      if dec is None:
         self.model = make_pipeline(StandardScaler(), SVC(random_state= 42))
      elif dec == "n":
         self.model = make_pipeline(Normalizer(), SVC(random_state= 42))
      elif dec == "r":
         self.model = make_pipeline(RobustScaler() , SVC(random_state= 42))      
         
      self.Name = "Support Vector Classifier" if name is None else name
      self.model.fit(self.X_train,self.y_train)
      self.y_pred = self.model.predict(self.X_test)
      self.feature_importance = feature_importances_


   def params_opt(self):
        parameters = {
            'svc__kernel': ["linear", "poly", "rbf", "sigmoid"],
            'svc__C': [0.1, 1, 5, 10]
        }
        self.opt_model = GridSearchCV(self.model, parameters, cv=5)
        self.opt_model.fit(self.X_train, self.y_train)
        self.y_pred_clf = self.opt_model.predict(self.X_test)

   def random_filter(self):  
      super().random_filter()
      self.model = SVC(random_state= 42)
      self.model.fit(self.X_train , self.y_train)

      self.Confusion_mat()
      self.get_metrics_score()      

## Rawdata
# The Rawdata ist packed into a Dataframe 
df = pd.read_excel(r"C:\Users\liwas\OneDrive\Desktop\Hochschule MÃ¼nchen\MBB8\Applied ML\Projektarbeit\chiefs_knife_dataset.xlsx")

## Target Class
Y = df['Ra']


ind_0 = np.where(Y < 0.13)
ind_1 = np.where((Y >= 0.13) & (Y <= 0.21))
ind_2 = np.where(Y > 0.21)


Y_class = Y.copy()
Y_class[ind_0] = 0
Y_class[ind_1] = 1
Y_class[ind_2] = 2

## Random Variable
# We are going use a randomly generated Variable to filter out the Variables who have little to no effect on the Output of the Model. 

df = df.iloc[:, 2:-17]
df = df.drop(columns="Linie")


#Random Variable 
df["Random_Variable"] = np.random.rand(len(df),1) * 100

# Model Intialization

rfc = RFC(df, Y_class)
rfc.Confusion_mat()
rfc.get_metrics_score()
rfc.random_filter()

#Filtered Dataframe is going to use for other Models to compare the Result with each other
df = rfc.df1
dt = Dec_tree(df, Y_class,rfc.model.feature_importances_)

# Only Tree Based Algorithms dont require the scaling of the Data.
# For SVC, the Scaling of the Data is required.

# First with Linear Models, if results are good, it could lead to the interpretation that the Data is linearly Seperable
#One hot / Label Encoder not needed because the Dataset only consists of numerical Features. The Names are removed cause they shouldnt play a part in classifying the Data.

svc_clf_s = SVM_clf(df, Y_class,rfc.model.feature_importances_ ,"Support Vector Classifier Standerdized")
svc_clf_n = SVM_clf(df, Y_class,rfc.model.feature_importances_ ,"Support Vector Classifier Normalized","n")
svc_clf_r = SVM_clf(df, Y_class,rfc.model.feature_importances_,"Support Vector Classifier Robust Scaled","r" )


# Output Analysis through Confusion Matrix

rfc.Confusion_mat()
dt.Confusion_mat()
svc_clf_s.Confusion_mat()
svc_clf_n.Confusion_mat()
svc_clf_r.Confusion_mat()



# Metric scores
dt.get_metrics_score()
svc_clf_s.get_metrics_score()
svc_clf_n.get_metrics_score()
svc_clf_r.get_metrics_score()


# Hyperparameter Optimization
rfc.params_opt()
dt.params_opt()


svc_clf_s.params_opt()
svc_clf_n.params_opt()
svc_clf_r.params_opt()